{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pandas.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first entries and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km)</th>\n",
       "      <th>Density (P/Km)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346.0</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797.0</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044.0</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272.0</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment  \\\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
       "3  01082688c6                                        happy bday!  positive   \n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
       "\n",
       "  Time of Tweet Age of User      Country  Population -2020  Land Area (Km)  \\\n",
       "0       morning        0-20  Afghanistan        38928346.0        652860.0   \n",
       "1          noon       21-30      Albania         2877797.0         27400.0   \n",
       "2         night       31-45      Algeria        43851044.0       2381740.0   \n",
       "3       morning       46-60      Andorra           77265.0           470.0   \n",
       "4          noon       60-70       Angola        32866272.0       1246700.0   \n",
       "\n",
       "   Density (P/Km)  \n",
       "0            60.0  \n",
       "1           105.0  \n",
       "2            18.0  \n",
       "3           164.0  \n",
       "4            26.0  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID              3534\n",
       "text                3534\n",
       "sentiment           3534\n",
       "Time of Tweet       3534\n",
       "Age of User         3534\n",
       "Country             3534\n",
       "Population -2020    3534\n",
       "Land Area (Km)      3534\n",
       "Density (P/Km)      3534\n",
       "dtype: int64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unnecessary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3  01082688c6                                        happy bday!  positive\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.drop([\"Land Area (Km)\", \"Density (P/Km)\", \"Age of User\", \"Country\", \"Population -2020\", \"Time of Tweet\"], axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in the columns \"textID\", \"text\" and \"sentiment\" we have some \"NaN\" values. Remove all rows with \"NaN\" in the \"textID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3  01082688c6                                        happy bday!  positive\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[dataset[\"textID\"].notna()]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map \"sentiment\" to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh          1\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...          2\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...          0\n",
       "3  01082688c6                                        happy bday!          2\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!          2"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "dataset[\"sentiment\"] = dataset[\"sentiment\"].map(classes)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an encoding for \"gpt-3.5-turbo\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert encoding.encode(\"Hello world!\") == [9906, 1917, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map all texts to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"text\"] = dataset[\"text\"].map(lambda text: encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>[5966, 3882, 315, 279, 1938, 220, 1795, 1129, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>[38147, 374, 1101, 2216, 13548, 320, 10872, 28...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>[697, 26540, 4295, 6383, 263, 2428, 77018, 447...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>[6380, 293, 1316, 0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>[1795, 1129, 15930, 275, 15959, 916, 14, 19, 8...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  sentiment\n",
       "0  f87dea47db  [5966, 3882, 315, 279, 1938, 220, 1795, 1129, ...          1\n",
       "1  96d74cb729  [38147, 374, 1101, 2216, 13548, 320, 10872, 28...          2\n",
       "2  eee518ae67  [697, 26540, 4295, 6383, 263, 2428, 77018, 447...          0\n",
       "3  01082688c6                               [6380, 293, 1316, 0]          2\n",
       "4  33987a8ee5  [1795, 1129, 15930, 275, 15959, 916, 14, 19, 8...          2"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the lengths of the tokenized texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"text\"].map(lambda text: len(text)).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the maximum length to retrieve the number of model inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"text\"].map(lambda text: len(text)).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we learned, that the longest text has a length of 54 tokens. We could use this as the number of inputs for our model. Thus we can not use this exact model for other datasets since the length of tokenized texts may be too big for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 token ~ 3/4 of a word\n",
    "        ~ 4 characters\n",
    "\n",
    "So 54 tokens are around 40 words in an average well-written english text.\n",
    "\n",
    "We will set the expected inputs to 50 words which are approximately 67 tokens. If we receive longer inputs in the future we will split the texts and persist which texts belong together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Create the pytorch model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define any number of nn.Modules (or use your current ones)\n",
    "encoder = nn.Sequential(\n",
    "    nn.Linear(67, 64), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(64, 32), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(32,16), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16,8), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8,4), \n",
    "    nn.ReLU()\n",
    ")\n",
    "decoder = nn.Sequential(\n",
    "    nn.Linear(4,8), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8,16), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 32), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(32, 64), \n",
    "    nn.Sigmoid(), \n",
    "    nn.Linear(64,1)\n",
    ")\n",
    "\n",
    "\n",
    "# define the LightningModule\n",
    "class SentimentModel(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.decoder(self.encoder(input))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = nn.functional.mse_loss(x_hat, y)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = nn.functional.cross_entropy(input=x_hat, target=y)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "# init the autoencoder\n",
    "sentiment_model = SentimentModel(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the \"DataLoader\" of \"PyTorch Lightning\". Therefore we will need a numpy tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tokens=67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_elements(list):\n",
    "    list_ = list + (number_of_tokens - len(list)) * [0]\n",
    "    return numpy.array(list_).reshape(67, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5966  3882   315 ...     0     0     0]\n",
      " [38147   374  1101 ...     0     0     0]\n",
      " [  697 26540  4295 ...     0     0     0]\n",
      " ...\n",
      " [  358  1440  1148 ...     0     0     0]\n",
      " [  646 78981  1148 ...     0     0     0]\n",
      " [ 1795  1129 15930 ...     0     0     0]]\n",
      "(3534, 67)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = dataset.filter([\"text\"]).map(lambda list: fill_missing_elements(list)).to_numpy()\n",
    "\n",
    "flattened_array = numpy.array([inner_array.flatten() for inner_array in input_tensor[:, 0]])\n",
    "print(flattened_array)\n",
    "print(flattened_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on our second dimension of the input tensor we have lists. We have to flatten those lists so we receive a tensor of the shape (3534, 67) which was our initial token length. If a list does not have enough tokens, we will append the rest with the value \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also create the tensor for the neural network outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim=2\n",
      "shape=(3534, 1)\n",
      "\n",
      "[[1]\n",
      " [2]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [2]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "output_tensor = dataset.filter([\"sentiment\"]).to_numpy()\n",
    "print(f\"ndim={output_tensor.ndim}\")\n",
    "print(f\"shape={output_tensor.shape}\")\n",
    "print()\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_sample = self.inputs[idx]\n",
    "        output_sample = self.outputs[idx]\n",
    "\n",
    "        return torch.Tensor(input_sample), torch.Tensor(output_sample)\n",
    "#        return {'input': torch.Tensor(input_sample), 'output': torch.Tensor(output_sample)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "class SentimentDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_inputs, train_outputs, val_inputs, val_outputs, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.train_dataset = SentimentDataset(train_inputs, train_outputs)\n",
    "        self.val_dataset = SentimentDataset(val_inputs, val_outputs)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val_dataset, batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5966,  3882,   315, ...,     0,     0,     0],\n",
       "       [38147,   374,  1101, ...,     0,     0,     0],\n",
       "       [  697, 26540,  4295, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  358,  1440,  1148, ...,     0,     0,     0],\n",
       "       [  646, 78981,  1148, ...,     0,     0,     0],\n",
       "       [ 1795,  1129, 15930, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datamodule = SentimentDataModule(flattened_array[70:, :], output_tensor[70:], flattened_array[:70, :], output_tensor[:70, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\MarcoSteinke\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 7.1 K \n",
      "1 | decoder | Sequential | 2.9 K \n",
      "---------------------------------------\n",
      "10.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.0 K    Total params\n",
      "0.040     Total estimated model params size (MB)\n",
      "c:\\Users\\MarcoSteinke\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb0d4e004354e07932d76047df0f849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=500, accelerator=\"gpu\")\n",
    "trainer.fit(sentiment_model, train_datamodule.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': tensor(0.4494)}"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainer.validate(sentiment_model, train_datamodule.val_dataloader())\n",
    "trainer.logged_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved a loss of under 5% which is okay for this naive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to tokenize inputs and prepare them for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    tokens = encoding.encode(text)\n",
    "    return fill_missing_elements(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This looks nice.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert prepare_input(text).shape == (number_of_tokens, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MarcoSteinke\\Desktop\\sentiment\\sentiment.ipynb Cell 54\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MarcoSteinke/Desktop/sentiment/sentiment.ipynb#Y120sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m prepare_input(text)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MarcoSteinke/Desktop/sentiment/sentiment.ipynb#Y120sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sentiment_model(\u001b[39minput\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\MarcoSteinke\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\MarcoSteinke\\Desktop\\sentiment\\sentiment.ipynb Cell 54\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MarcoSteinke/Desktop/sentiment/sentiment.ipynb#Y120sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MarcoSteinke/Desktop/sentiment/sentiment.ipynb#Y120sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\u001b[39minput\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\MarcoSteinke\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\MarcoSteinke\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\MarcoSteinke\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\MarcoSteinke\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "input = prepare_input(text)\n",
    "\n",
    "sentiment_model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
